# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

### ОТВЕТ

Для микросервисной архитектуры критически важно обеспечить непрерывную интеграцию и непрерывную поставку. Код каждого сервиса должен храниться в отдельном репозитории, и для каждого сервиса собирается отдельный артефакт.

#### Предлагаемое решение: **GitLab CI/CD**

**Компоненты решения:**
1. **GitLab** — облачная платформа для хранения исходного кода и CI/CD
2. **GitLab Shared Runners** — встроенные агенты сборки, доступные по умолчанию в GitLab
3. **GitLab Runner** (опционально) — возможность развернуть собственные агенты сборки на собственных серверах для дополнительного контроля
4. **Docker Registry** (встроенный в GitLab или внешний) — для хранения результатов сборки - готовых Docker-образов

#### Соответствие требованиям:

##### Облачная система

GitLab доступен как облачный сервис или может быть развернут в собственном облаке.

##### Система контроля версий Git

Является полноценной Git-системой с веб-интерфейсом, соответственно может хранить множество репозиториев, соответствующих отдельным сервисам.

##### Репозиторий на каждый сервис

Каждый микросервис имеет отдельный репозиторий в GitLab, что соответствует принципам раздельного хранения кода сервисов.

##### Запуск сборки по событию из системы контроля версий

Поддерживает автоматический запуск pipeline при push, merge request, создании тегов.

##### Запуск сборки по кнопке с указанием параметров

Запуск сборки по кнопке с параметрами обеспечивается через manual jobs (в .gitlab-ci.yml указывается when: manual для job), затем при запуске будет возможность указать переменные окружения.

##### Возможность привязать настройки к каждой сборке

Настройки к каждой сборке можно привязать через переменные окружения на уровне проекта, pipeline или job.

##### Возможность создания шаблонов для различных конфигураций сборок

Реализуется через includes в .gitlab-ci.yml, шаблоны проектов и общие конфигурации.

##### Возможность безопасного хранения секретных данных

Обеспечивается через CI/CD Variables с маскированием, а также интеграцией с External Secrets и HashiCorp Vault.

##### Несколько конфигураций для сборки из одного репозитория

Поддерживается через множественные pipeline с использованием includes и правил в .gitlab-ci.yml.

##### Кастомные шаги при сборке

Настраиваются через .gitlab-ci.yml с возможностью выполнения любых команд и скриптов.

##### Собственные докер-образы для сборки проектов

Хранятся во встроенном Container Registry GitLab или внешнем registry.

##### Возможность развернуть агентов сборки на собственных серверах

GitLab предоставляет shared runners, также есть возможность развернуть раннеры на собственных серверах.

##### Возможность параллельного запуска нескольких сборок

Параллельный запуск нескольких сборок обеспечивается множественными runners, которые могут одновременно выполнять разные пайплайны из разных веток, из разных репозирториев.

##### Возможность параллельного запуска тестов

Параллельный запуск тестов реализуется через параллельные test jobs с возможностью разделения тестов на группы. Для параллельного запуска должны быть свободные раннеры, если свободных нет, jobs будут запускаться последовательно.

#### Принципы работы:

1. **Хранение кода**: Каждый микросервис имеет отдельный репозиторий в GitLab, что соответствует принципу раздельного хранения кода сервисов.

2. **Непрерывная интеграция**: При каждом коммите автоматически запускается pipeline:
   - Выполняет сборку артефакта для конкретного сервиса
   - Запускает unit-тесты
   - Публикует артефакт в репозиторий

3. **Непрерывная поставка**: Pipeline может включать этапы:
   - Сборка
   - Тестирование
   - Развертывание на тестовые стенды
   - Ручное подтверждение для выкладки в production

4. **Агенты сборки**: 
   - По умолчанию GitLab предоставляет shared runners, которые доступны сразу после создания проекта
   - При необходимости можно развернуть собственные GitLab Runner на собственных серверах
   - GitLab поддерживает параллельное выполнение сборок как на shared, так и на собственных runners

#### Обоснование выбора:

- **Интеграция**: Единая платформа упрощает управление
- **Гибкость**: Полная настройка через .gitlab-ci.yml позволяет реализовать любые сценарии сборки
- **Масштабируемость**: Поддержка множественных runners обеспечивает параллельную работу
- **Безопасность**: Встроенные механизмы управления секретами
- **Соответствие принципам**: Реализует подходы непрерывной интеграции и поставки

Рассматривая альтернативы стоит упомянуть GitHub Actions. Из более гибких, но сложных: Jenkins, TeamCity (коммерческое решение с хорошей поддержкой).

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

### ОТВЕТ

Сбор логов является важной частью мониторинга микросервисной архитектуры. Логи собираются с каждого хоста и централизуются для анализа.

#### Предлагаемое решение: **ELK Stack (Elasticsearch, Logstash, Kibana)**

**Компоненты решения:**
1. **Filebeat** — агент для сбора логов с хостов (сбор из stdout)
2. **Logstash** — обработка логов
3. **Elasticsearch** — централизованное хранилище логов
4. **Kibana** — пользовательский интерфейс для анализа логов

#### Соответствие требованиям:

##### Сбор логов в центральное хранилище со всех хостов

Filebeat устанавливается на каждом хосте и отправляет логи в Elasticsearch, обеспечивая централизованное хранение.

##### Минимальные требования к приложениям, сбор логов из stdout

Filebeat собирает логи из stdout/stderr контейнеров и приложений, минимальное потребление ресурсов, не требует изменений в приложениях.

##### Гарантированная доставка логов до центрального хранилища

Filebeat поддерживает очереди на диске, автоматические повторные попытки доставки при сбоях сети и подтверждение получения от Elasticsearch, что гарантирует доставку логов.

##### Обеспечение поиска и фильтрации по записям логов

Elasticsearch обеспечивает полнотекстовый поиск и индексацию логов, Kibana предоставляет фильтры и запросы для поиска и фильтрации по различным критериям.

##### Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов

Kibana предоставляет веб-интерфейс с возможностью настройки ролей и прав доступа, позволяя разработчикам иметь доступ к логам своих сервисов для поиска и анализа.

##### Возможность дать ссылку на сохранённый поиск по записям логов

Kibana позволяет сохранять поисковые запросы и создавать на них прямые ссылки, которые можно шарить с другими пользователями.

#### Принцип работы:

1. **Сбор логов**: 
   - Filebeat устанавливается на каждом хосте как легковесный агент
   - Собирает логи из stdout/stderr

2. **Доставка логов**:
   - Filebeat, используя механизмы, гарантирующие доставку, отправляет логи в Elasticsearch

3. **Хранение и индексация**:
   - Elasticsearch индексирует логи для быстрого поиска

4. **Анализ и поиск**:
   - Kibana предоставляет веб-интерфейс для поиска логов
   - Поддержка сложных запросов (KQL, Lucene)
   - Фильтрация по времени, уровню логов, сервисам, хостам
   - Визуализация логов через графики и дашборды

5. **Доступ разработчиков**:
   - Kibana поддерживает настройку ролей и прав доступа
   - Разработчики могут иметь доступ только к логам своих сервисов
   - Сохраненные поисковые запросы можно шарить через прямые ссылки


#### Обоснование выбора:

ELK Stack является оптимальным решением для сбора и анализа логов в микросервисной архитектуре. Легковесный агент Filebeat не требует изменений в приложениях и обеспечивает гарантированную доставку логов благодаря механизмам персистентных очередей и автоматических повторных попыток.

Elasticsearch обеспечивает надежное хранение и индексацию логов с возможностью горизонтального масштабирования, а мощный поисковый движок поддерживает сложные запросы и фильтрацию.

Kibana предоставляет интуитивный веб-интерфейс для анализа логов с настройкой прав доступа для разработчиков.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

### ОТВЕТ

Мониторинг включает сбор метрик, сбор логов и сбор трассировки. Каждый сервис публикует метрики, которые регулярно считываются и сохраняются системой мониторинга.

#### Предлагаемое решение: **Prometheus + Grafana**

**Компоненты решения:**
1. **Prometheus** — система сбора и хранения метрик
2. **Node Exporter** — агент для сбора метрик хостов
3. **cAdvisor** — сбор метрик контейнеров и сервисов
4. **Grafana** — UI для визуализации и анализа метрик

#### Соответствие требованиям:

##### Сбор метрик со всех хостов, обслуживающих систему

Prometheus опрашивает все хосты через pull-модель, собирая метрики с каждого хоста по расписанию.

##### Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network

Node Exporter устанавливается на каждом хосте и собирает системные метрики: CPU (использование, load average), RAM (использование, swap), HDD (использование, I/O), Network (трафик, ошибки), экспортируя их через HTTP endpoint `/metrics`.

##### Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network

cAdvisor собирает метрики контейнеров (Docker/Kubernetes) для каждого сервиса: CPU usage, Memory usage, Disk I/O, Network I/O. Метрики помечаются labels (service_name, container_id, host) для идентификации конкретного сервиса.

##### Сбор метрик, специфичных для каждого сервиса

Каждый микросервис экспортирует свои специфичные метрики через HTTP endpoint `/metrics` (используя Prometheus client libraries), включая бизнес-метрики, количество запросов, время ответа, ошибки. Prometheus собирает эти метрики по расписанию.

##### Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию

Grafana подключается к Prometheus как источнику данных, поддерживает PromQL (Prometheus Query Language) для запросов, агрегацию данных и математические операции.

##### Пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы

Grafana позволяет создавать и настраивать дашборды с различными типами визуализаций (line, bar, gauge, heatmap), настраивать панели для отслеживания состояния хостов и сервисов.

#### Принципы работы:

1. **Сбор метрик хостов**:
   - Node Exporter устанавливается на каждом хосте
   - Собирает метрики, экспортирует метрики через HTTP endpoint
   - Prometheus периодически опрашивает этот endpoint

2. **Сбор метрик сервисов**:
   - cAdvisor собирает метрики контейнеров (Docker/Kubernetes)
   - Для каждого сервиса собирает: CPU usage, Memory usage, Disk I/O, Network I/O
   - Метрики помечаются с помощью labels (service_name, container_id, host)
   - Prometheus собирает метрики из cAdvisor

3. **Специфичные метрики сервисов**:
   - Каждый микросервис должен экспортировать свои метрики через HTTP endpoint `/metrics`
   - Метрики могут включать: количество запросов, время ответа, ошибки, бизнес-метрики
   - Prometheus собирает эти метрики по расписанию

4. **Хранение метрик**:
   - Prometheus хранит метрики во временной базе данных (TSDB) с эффективным сжатием временных рядов

5. **Визуализация и анализ**:
   - Grafana подключается к Prometheus как источнику данных
   - Поддержка PromQL (Prometheus Query Language) для запросов
   - Создание дашбордов с различными типами графиков (line, bar, gauge, heatmap)
   - Агрегация данных (sum, avg, rate, increase)
   - Алерты на основе метрик

#### Обоснование выбора:

Prometheus + Grafana является оптимальным решением для мониторинга микросервисной архитектуры. Pull-модель Prometheus, при которой система сама опрашивает метрики, упрощает масштабирование и управление.

Временная база данных (TSDB) оптимизирована для хранения временных рядов с эффективным сжатием данных. Язык запросов PromQL позволяет выполнять сложные запросы и агрегации метрик, а богатая экосистема готовых exporters обеспечивает сбор метрик из различных систем без дополнительной разработки.

Grafana предоставляет мощные возможности для создания настраиваемых дашбордов с различными типами визуализаций, что позволяет эффективно отслеживать состояние хостов и сервисов. Решение обеспечивает все необходимые требования для мониторинга распределенной системы.
